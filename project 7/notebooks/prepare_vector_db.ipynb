{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426eaa04",
   "metadata": {},
   "source": [
    "# Vector Database Preparation for Wardrobe AI\n",
    "\n",
    "This notebook prepares the vector database for the Wardrobe AI application by processing clothing images and creating embeddings for similarity search.\n",
    "\n",
    "## Overview\n",
    "- Process t-shirt and pant images from data samples\n",
    "- Generate AI-powered descriptions using OpenAI's vision models\n",
    "- Create embeddings and populate ChromaDB vector store\n",
    "- Setup MultiVectorRetriever for efficient image retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b42a4",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Library Imports\n",
    "\n",
    "Import all necessary libraries and load environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# AI and ML libraries\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Verify OpenAI API key is loaded\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è  Warning: OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"Please add your OpenAI API key to a .env file\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd52b5",
   "metadata": {},
   "source": [
    "## 2. Configuration and Constants\n",
    "\n",
    "Define all configuration variables and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ba158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"embeddings_model\": \"text-embedding-3-small\",\n",
    "    \"vision_model\": \"gpt-4o-mini\",\n",
    "    \"image_formats\": [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"],\n",
    "    \"target_size\": (512, 512),\n",
    "    \"chroma_persist_dir\": \"../chroma_langchain_db\",\n",
    "    \"docstore_dir\": \"../TSHIRT_DOCSTORE\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "PATHS = {\n",
    "    \"tshirt_samples\": \"../data/tshirt_samples\",\n",
    "    \"pant_samples\": \"../data/pant_samples\",\n",
    "    \"tshirt_dataset\": \"../tshirt\",\n",
    "    \"pant_dataset\": \"../pant-dataset\"\n",
    "}\n",
    "\n",
    "# Collection names\n",
    "COLLECTIONS = {\n",
    "    \"tshirt\": \"tshirt\",\n",
    "    \"pant\": \"pant\"\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"üìÅ T-shirt samples: {PATHS['tshirt_samples']}\")\n",
    "print(f\"üìÅ Pant samples: {PATHS['pant_samples']}\")\n",
    "print(f\"üîç Embeddings model: {CONFIG['embeddings_model']}\")\n",
    "print(f\"üëÅÔ∏è Vision model: {CONFIG['vision_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73623f0d",
   "metadata": {},
   "source": [
    "## 3. Image Processing Functions\n",
    "\n",
    "Implement functions for image loading, validation, and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_image(image_path):\n",
    "    \"\"\"\n",
    "    Validate if an image file is readable and has proper format.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if image is valid, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img.verify()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Invalid image {image_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def resize_image(image_path, target_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Resize image to target size while maintaining aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the input image\n",
    "        target_size (tuple): Target size (width, height)\n",
    "        \n",
    "    Returns:\n",
    "        PIL.Image: Resized image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            # Convert to RGB if necessary\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Resize with aspect ratio preservation\n",
    "            img.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Create new image with target size and paste resized image\n",
    "            new_img = Image.new('RGB', target_size, (255, 255, 255))\n",
    "            paste_x = (target_size[0] - img.width) // 2\n",
    "            paste_y = (target_size[1] - img.height) // 2\n",
    "            new_img.paste(img, (paste_x, paste_y))\n",
    "            \n",
    "            return new_img\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error resizing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_image_files(directory):\n",
    "    \"\"\"\n",
    "    Get all valid image files from a directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Directory path\n",
    "        \n",
    "    Returns:\n",
    "        list: List of valid image file paths\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"‚ö†Ô∏è  Directory not found: {directory}\")\n",
    "        return []\n",
    "    \n",
    "    image_files = []\n",
    "    for ext in CONFIG['image_formats']:\n",
    "        pattern = os.path.join(directory, f\"*{ext}\")\n",
    "        image_files.extend(glob.glob(pattern))\n",
    "        pattern = os.path.join(directory, f\"*{ext.upper()}\")\n",
    "        image_files.extend(glob.glob(pattern))\n",
    "    \n",
    "    # Validate images\n",
    "    valid_images = []\n",
    "    for img_path in image_files:\n",
    "        if validate_image(img_path):\n",
    "            valid_images.append(img_path)\n",
    "    \n",
    "    print(f\"üì∏ Found {len(valid_images)} valid images in {directory}\")\n",
    "    return valid_images\n",
    "\n",
    "# Test the functions\n",
    "print(\"\\nüß™ Testing image processing functions...\")\n",
    "tshirt_files = get_image_files(PATHS['tshirt_samples'])\n",
    "pant_files = get_image_files(PATHS['pant_samples'])\n",
    "\n",
    "# Also check larger datasets if they exist\n",
    "tshirt_dataset_files = get_image_files(PATHS['tshirt_dataset'])\n",
    "pant_dataset_files = get_image_files(PATHS['pant_dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93306dc6",
   "metadata": {},
   "source": [
    "## 4. Vector Database Setup\n",
    "\n",
    "Initialize ChromaDB collections and configure the retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef52d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_vector_stores():\n",
    "    \"\"\"\n",
    "    Initialize ChromaDB vector stores and document store.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (tshirt_retriever, pant_retriever, file_store)\n",
    "    \"\"\"\n",
    "    # Initialize embeddings\n",
    "    embeddings = OpenAIEmbeddings(model=CONFIG['embeddings_model'])\n",
    "    \n",
    "    # Initialize document store\n",
    "    file_store = LocalFileStore(CONFIG['docstore_dir'])\n",
    "    \n",
    "    # Initialize ChromaDB collections\n",
    "    tshirt_vectorstore = Chroma(\n",
    "        collection_name=COLLECTIONS['tshirt'],\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=CONFIG['chroma_persist_dir']\n",
    "    )\n",
    "    \n",
    "    pant_vectorstore = Chroma(\n",
    "        collection_name=COLLECTIONS['pant'],\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=CONFIG['chroma_persist_dir']\n",
    "    )\n",
    "    \n",
    "    # Initialize retrievers\n",
    "    tshirt_retriever = MultiVectorRetriever(\n",
    "        vectorstore=tshirt_vectorstore,\n",
    "        docstore=file_store,\n",
    "        id_key=\"doc_id\",\n",
    "        return_doc_ids=True\n",
    "    )\n",
    "    \n",
    "    pant_retriever = MultiVectorRetriever(\n",
    "        vectorstore=pant_vectorstore,\n",
    "        docstore=file_store,\n",
    "        id_key=\"doc_id\",\n",
    "        return_doc_ids=True\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Vector stores initialized successfully\")\n",
    "    print(f\"üìÇ ChromaDB directory: {CONFIG['chroma_persist_dir']}\")\n",
    "    print(f\"üìÇ Document store: {CONFIG['docstore_dir']}\")\n",
    "    \n",
    "    return tshirt_retriever, pant_retriever, file_store\n",
    "\n",
    "# Initialize vector stores\n",
    "tshirt_retriever, pant_retriever, file_store = setup_vector_stores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16f97f",
   "metadata": {},
   "source": [
    "## 5. Image Encoding and Base64 Conversion\n",
    "\n",
    "Functions to encode images for storage and AI processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Encode an image file to base64 string.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        str: Base64 encoded string or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            base64_string = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "        return base64_string\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error encoding {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def pil_to_base64(pil_image, format='PNG'):\n",
    "    \"\"\"\n",
    "    Convert PIL Image to base64 string.\n",
    "    \n",
    "    Args:\n",
    "        pil_image (PIL.Image): PIL Image object\n",
    "        format (str): Image format (PNG, JPEG, etc.)\n",
    "        \n",
    "    Returns:\n",
    "        str: Base64 encoded string\n",
    "    \"\"\"\n",
    "    from io import BytesIO\n",
    "    \n",
    "    buffer = BytesIO()\n",
    "    pil_image.save(buffer, format=format)\n",
    "    img_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "def create_base64_data_url(base64_string, image_format='png'):\n",
    "    \"\"\"\n",
    "    Create a data URL from base64 string.\n",
    "    \n",
    "    Args:\n",
    "        base64_string (str): Base64 encoded image\n",
    "        image_format (str): Image format\n",
    "        \n",
    "    Returns:\n",
    "        str: Data URL string\n",
    "    \"\"\"\n",
    "    return f\"data:image/{image_format};base64,{base64_string}\"\n",
    "\n",
    "# Test encoding function\n",
    "print(\"\\nüß™ Testing image encoding...\")\n",
    "if tshirt_files:\n",
    "    test_image = tshirt_files[0]\n",
    "    encoded = encode_image_to_base64(test_image)\n",
    "    if encoded:\n",
    "        print(f\"‚úÖ Successfully encoded {os.path.basename(test_image)}\")\n",
    "        print(f\"üìè Encoded length: {len(encoded)} characters\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to encode test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805881a",
   "metadata": {},
   "source": [
    "## 6. Embedding Generation and Storage\n",
    "\n",
    "Generate AI descriptions and embeddings for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a0ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_description(image_base64, clothing_type, model_name=None):\n",
    "    \"\"\"\n",
    "    Generate description of clothing item using OpenAI's vision model.\n",
    "    \n",
    "    Args:\n",
    "        image_base64 (str): Base64 encoded image\n",
    "        clothing_type (str): Type of clothing ('tshirt' or 'pant')\n",
    "        model_name (str): Model name to use\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated description or None if error\n",
    "    \"\"\"\n",
    "    if model_name is None:\n",
    "        model_name = CONFIG['vision_model']\n",
    "    \n",
    "    try:\n",
    "        chat = ChatOpenAI(model=model_name, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        \n",
    "        if clothing_type.lower() == 'tshirt':\n",
    "            prompt = \"\"\"You are an assistant tasked with summarizing t-shirt images for retrieval.\n",
    "            These summaries will be embedded and used to retrieve the raw image.\n",
    "            Give a concise summary of the t-shirt that is well optimized for retrieval in a single line.\n",
    "            Focus on style, color, patterns, neckline, sleeves, and any distinctive features.\n",
    "            Do not talk about anything else just the t-shirt you see in the image.\"\"\"\n",
    "        else:  # pant\n",
    "            prompt = \"\"\"You are an assistant tasked with summarizing pant images for retrieval.\n",
    "            These summaries will be embedded and used to retrieve the raw image.\n",
    "            Give a concise summary of the pants that is well optimized for retrieval in a single line.\n",
    "            Focus on style, color, fit, material, and any distinctive features.\n",
    "            Do not talk about anything else just the pants you see in the image.\"\"\"\n",
    "        \n",
    "        msg = chat.invoke([\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        return msg.content.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating description: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_single_image(image_path, clothing_type, retriever, file_store):\n",
    "    \"\"\"\n",
    "    Process a single image and add it to the vector store.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image\n",
    "        clothing_type (str): Type of clothing\n",
    "        retriever: Vector retriever object\n",
    "        file_store: Document store object\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate unique document ID\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Resize and encode image\n",
    "        resized_img = resize_image(image_path, CONFIG['target_size'])\n",
    "        if resized_img is None:\n",
    "            return False\n",
    "        \n",
    "        base64_encoded = pil_to_base64(resized_img)\n",
    "        if not base64_encoded:\n",
    "            return False\n",
    "        \n",
    "        # Generate description\n",
    "        description = generate_image_description(base64_encoded, clothing_type)\n",
    "        if not description:\n",
    "            print(f\"‚ö†Ô∏è  Could not generate description for {image_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Store in document store\n",
    "        file_store.mset([(doc_id, base64_encoded.encode('utf-8'))])\n",
    "        \n",
    "        # Create document with metadata\n",
    "        doc = Document(\n",
    "            page_content=description,\n",
    "            metadata={\n",
    "                \"doc_id\": doc_id,\n",
    "                \"source\": image_path,\n",
    "                \"clothing_type\": clothing_type,\n",
    "                \"description\": description\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Add to vector store\n",
    "        retriever.vectorstore.add_documents([doc])\n",
    "        \n",
    "        print(f\"‚úÖ Processed: {os.path.basename(image_path)} -> {description[:50]}...\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {image_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test with a single image\n",
    "print(\"\\nüß™ Testing single image processing...\")\n",
    "if tshirt_files:\n",
    "    success = process_single_image(\n",
    "        tshirt_files[0], \n",
    "        'tshirt', \n",
    "        tshirt_retriever, \n",
    "        file_store\n",
    "    )\n",
    "    if success:\n",
    "        print(\"‚úÖ Single image processing test passed\")\n",
    "    else:\n",
    "        print(\"‚ùå Single image processing test failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c752f",
   "metadata": {},
   "source": [
    "## 7. Vector Store Population\n",
    "\n",
    "Batch process all sample images and populate the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_vector_store(image_files, clothing_type, retriever, file_store, max_images=None):\n",
    "    \"\"\"\n",
    "    Populate vector store with multiple images.\n",
    "    \n",
    "    Args:\n",
    "        image_files (list): List of image file paths\n",
    "        clothing_type (str): Type of clothing\n",
    "        retriever: Vector retriever object\n",
    "        file_store: Document store object\n",
    "        max_images (int): Maximum number of images to process (None for all)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing statistics\n",
    "    \"\"\"\n",
    "    if max_images:\n",
    "        image_files = image_files[:max_images]\n",
    "    \n",
    "    stats = {\n",
    "        'total': len(image_files),\n",
    "        'successful': 0,\n",
    "        'failed': 0,\n",
    "        'descriptions': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüöÄ Processing {stats['total']} {clothing_type} images...\")\n",
    "    \n",
    "    for i, image_path in enumerate(image_files, 1):\n",
    "        print(f\"Progress: {i}/{stats['total']} - {os.path.basename(image_path)}\")\n",
    "        \n",
    "        success = process_single_image(image_path, clothing_type, retriever, file_store)\n",
    "        \n",
    "        if success:\n",
    "            stats['successful'] += 1\n",
    "        else:\n",
    "            stats['failed'] += 1\n",
    "        \n",
    "        # Progress update every 10 images\n",
    "        if i % 10 == 0:\n",
    "            print(f\"üìä Progress: {i}/{stats['total']} ({stats['successful']} successful, {stats['failed']} failed)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ {clothing_type.capitalize()} processing complete!\")\n",
    "    print(f\"üìä Successful: {stats['successful']}/{stats['total']}\")\n",
    "    print(f\"‚ùå Failed: {stats['failed']}/{stats['total']}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Process T-shirt images (limit to first 20 from samples for demo)\n",
    "print(\"=\" * 60)\n",
    "print(\"PROCESSING T-SHIRT IMAGES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine sample and dataset files, prioritizing samples\n",
    "all_tshirt_files = tshirt_files + tshirt_dataset_files[:20] if tshirt_dataset_files else tshirt_files\n",
    "tshirt_stats = populate_vector_store(\n",
    "    all_tshirt_files[:25],  # Limit for demo\n",
    "    'tshirt',\n",
    "    tshirt_retriever,\n",
    "    file_store\n",
    ")\n",
    "\n",
    "# Process Pant images\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROCESSING PANT IMAGES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine sample and dataset files, prioritizing samples\n",
    "all_pant_files = pant_files + pant_dataset_files[:20] if pant_dataset_files else pant_files\n",
    "pant_stats = populate_vector_store(\n",
    "    all_pant_files[:25],  # Limit for demo\n",
    "    'pant',\n",
    "    pant_retriever,\n",
    "    file_store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91789b6e",
   "metadata": {},
   "source": [
    "## 8. Database Validation and Testing\n",
    "\n",
    "Test the vector database functionality with sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3141cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_similarity_search(retriever, query, collection_name, top_k=3):\n",
    "    \"\"\"\n",
    "    Test similarity search functionality.\n",
    "    \n",
    "    Args:\n",
    "        retriever: Vector retriever object\n",
    "        query (str): Search query\n",
    "        collection_name (str): Name of the collection\n",
    "        top_k (int): Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        list: Search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nüîç Testing {collection_name} search with query: '{query}'\")\n",
    "        \n",
    "        results = retriever.vectorstore.similarity_search(query, k=top_k)\n",
    "        \n",
    "        print(f\"üìã Found {len(results)} results:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"{i}. {result.page_content}\")\n",
    "            if 'doc_id' in result.metadata:\n",
    "                print(f\"   Doc ID: {result.metadata['doc_id']}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during search: {e}\")\n",
    "        return []\n",
    "\n",
    "def test_image_retrieval(retriever, file_store, query, collection_name):\n",
    "    \"\"\"\n",
    "    Test complete image retrieval workflow.\n",
    "    \n",
    "    Args:\n",
    "        retriever: Vector retriever object\n",
    "        file_store: Document store object\n",
    "        query (str): Search query\n",
    "        collection_name (str): Name of the collection\n",
    "        \n",
    "    Returns:\n",
    "        str: Base64 encoded image or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nüñºÔ∏è  Testing image retrieval for {collection_name}: '{query}'\")\n",
    "        \n",
    "        # Search for similar items\n",
    "        results = retriever.vectorstore.similarity_search(query, k=1)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"‚ùå No results found\")\n",
    "            return None\n",
    "        \n",
    "        # Get document ID\n",
    "        doc_id = results[0].metadata.get('doc_id')\n",
    "        if not doc_id:\n",
    "            print(\"‚ùå No document ID found\")\n",
    "            return None\n",
    "        \n",
    "        # Retrieve image from document store\n",
    "        image_bytes = file_store.mget([doc_id])\n",
    "        if not image_bytes or not image_bytes[0]:\n",
    "            print(\"‚ùå Could not retrieve image from document store\")\n",
    "            return None\n",
    "        \n",
    "        image_base64 = image_bytes[0].decode(\"utf-8\")\n",
    "        print(f\"‚úÖ Successfully retrieved image (length: {len(image_base64)})\")\n",
    "        print(f\"üìù Description: {results[0].page_content}\")\n",
    "        \n",
    "        return image_base64\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during image retrieval: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test queries\n",
    "test_queries = {\n",
    "    'tshirt': [\n",
    "        \"red polo shirt\",\n",
    "        \"casual white t-shirt\",\n",
    "        \"vintage band tee\",\n",
    "        \"athletic wear\"\n",
    "    ],\n",
    "    'pant': [\n",
    "        \"blue jeans\",\n",
    "        \"black formal pants\",\n",
    "        \"casual khakis\",\n",
    "        \"athletic shorts\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING VECTOR DATABASE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test T-shirt searches\n",
    "print(\"\\nüîç Testing T-shirt Collection:\")\n",
    "for query in test_queries['tshirt'][:2]:  # Test first 2 queries\n",
    "    results = test_similarity_search(tshirt_retriever, query, \"T-shirt\", top_k=2)\n",
    "    if results:\n",
    "        # Test full retrieval for first result\n",
    "        image_data = test_image_retrieval(tshirt_retriever, file_store, query, \"T-shirt\")\n",
    "\n",
    "# Test Pant searches\n",
    "print(\"\\nüîç Testing Pant Collection:\")\n",
    "for query in test_queries['pant'][:2]:  # Test first 2 queries\n",
    "    results = test_similarity_search(pant_retriever, query, \"Pant\", top_k=2)\n",
    "    if results:\n",
    "        # Test full retrieval for first result\n",
    "        image_data = test_image_retrieval(pant_retriever, file_store, query, \"Pant\")\n",
    "\n",
    "# Database statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATABASE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    tshirt_count = tshirt_retriever.vectorstore._collection.count()\n",
    "    pant_count = pant_retriever.vectorstore._collection.count()\n",
    "    \n",
    "    print(f\"üìä T-shirt collection: {tshirt_count} items\")\n",
    "    print(f\"üìä Pant collection: {pant_count} items\")\n",
    "    print(f\"üìä Total items: {tshirt_count + pant_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not get collection counts: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Vector database preparation complete!\")\n",
    "print(\"üöÄ Ready to run the Wardrobe AI application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ae9ab",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The vector database has been successfully prepared with:\n",
    "\n",
    "1. **Image Processing**: Resized and validated clothing images\n",
    "2. **AI Descriptions**: Generated using OpenAI's vision models\n",
    "3. **Vector Embeddings**: Created using OpenAI's embedding models\n",
    "4. **ChromaDB Storage**: Organized in separate collections for t-shirts and pants\n",
    "5. **Document Store**: Base64 encoded images stored for retrieval\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Run the main Streamlit application: `streamlit run src/app.py`\n",
    "2. Upload a pant image to get t-shirt recommendations\n",
    "3. Try the AR overlay feature with your webcam\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The database is persistent and will be saved to disk\n",
    "- You can add more images to the data folders and re-run this notebook\n",
    "- Adjust the `max_images` parameter to process more/fewer images\n",
    "- Monitor OpenAI API usage when processing large image datasets"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
